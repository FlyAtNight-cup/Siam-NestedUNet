{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vJQ_leiiLo7sTjogVWX9GXd7s9Maa9EO",
      "authorship_tag": "ABX9TyOR4oJ15LSgTS+S3MP19EjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "198abe375f91401eb291a0980d294bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb9ddb9d77bb447d82ed0359d3b0df9b",
              "IPY_MODEL_1a02a54a0fb946cbb3c4bb4159e65ad5",
              "IPY_MODEL_05066ef9540048b78466dfc1790e915a"
            ],
            "layout": "IPY_MODEL_ed78d6b766fa4ba99a667bc83e604d0f"
          }
        },
        "bb9ddb9d77bb447d82ed0359d3b0df9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b530aca4caa4bbdbfc7b513191eb2a1",
            "placeholder": "​",
            "style": "IPY_MODEL_538951e679764b33918df9f7c95e13a3",
            "value": "epoch 0 info 0 - 2:   0%"
          }
        },
        "1a02a54a0fb946cbb3c4bb4159e65ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2d2d2fa0f0467ba443af0988e47010",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1450abc1e9f041e2aa3d43e5ef348c8f",
            "value": 0
          }
        },
        "05066ef9540048b78466dfc1790e915a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4206d9d9d8884c0da337e0406537f8d1",
            "placeholder": "​",
            "style": "IPY_MODEL_4c1f435404024bd29d8e2a2a84e258ba",
            "value": " 0/220 [00:00&lt;?, ?it/s]"
          }
        },
        "ed78d6b766fa4ba99a667bc83e604d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b530aca4caa4bbdbfc7b513191eb2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538951e679764b33918df9f7c95e13a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba2d2d2fa0f0467ba443af0988e47010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1450abc1e9f041e2aa3d43e5ef348c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4206d9d9d8884c0da337e0406537f8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1f435404024bd29d8e2a2a84e258ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAtNight-cup/Siam-NestedUNet/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
        "from utils.parser import get_parser_with_args\n",
        "from utils.helpers import (get_loaders, get_criterion,\n",
        "                           load_model, initialize_metrics, get_mean_metrics,\n",
        "                           set_metrics)\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vYlhMJUw60WI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/likyoo/Siam-NestedUNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPgEqnOq-V9g",
        "outputId": "44671a79-975a-4590-9494-92380f85559d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Siam-NestedUNet'...\n",
            "remote: Enumerating objects: 533, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 533 (delta 24), reused 22 (delta 19), pack-reused 499\u001b[K\n",
            "Receiving objects: 100% (533/533), 2.35 MiB | 5.24 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_torch(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "FUpkyOAJ7rSq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Initialize Parser and define arguments\n",
        "\"\"\"\n",
        "parser, metadata = get_parser_with_args()\n",
        "opt = parser.parse_args(args=[])\n",
        "\n",
        "\"\"\"\n",
        "Initialize experiments log\n",
        "\"\"\"\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "writer = SummaryWriter(opt.log_dir + f'/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}/')\n",
        "\n",
        "\"\"\"\n",
        "Set up environment: define paths, download data, and set device\n",
        "\"\"\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "logging.info('GPU AVAILABLE? ' + str(torch.cuda.is_available()))\n",
        "\n",
        "\n",
        "seed_torch(seed=777)\n",
        "\n",
        "\n",
        "train_loader, val_loader = get_loaders(opt)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Load Model then define other aspects of the model\n",
        "\"\"\"\n",
        "logging.info('LOADING Model')\n",
        "torch.cuda.empty_cache()\n",
        "model = load_model(opt, dev)\n",
        "\n",
        "criterion = get_criterion(opt)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate) # Be careful when you adjust learning rate, you can refer to the linear scaling rule\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.5)\n"
      ],
      "metadata": {
        "id": "E47zHjMA7t_E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " Set starting values\n",
        "\"\"\"\n",
        "best_metrics = {'cd_f1scores': -1, 'cd_recalls': -1, 'cd_precisions': -1}\n",
        "logging.info('STARTING training')\n",
        "total_step = -1\n",
        "\n",
        "for epoch in range(opt.epochs):\n",
        "    train_metrics = initialize_metrics()\n",
        "    val_metrics = initialize_metrics()\n",
        "\n",
        "    \"\"\"\n",
        "    Begin Training\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    logging.info('SET model mode to train!')\n",
        "    batch_iter = 0\n",
        "    tbar = tqdm(train_loader)\n",
        "    for batch_img1, batch_img2, labels in tbar:\n",
        "        torch.cuda.empty_cache()\n",
        "        tbar.set_description(\"epoch {} info \".format(epoch) + str(batch_iter) + \" - \" + str(batch_iter+opt.batch_size))\n",
        "        batch_iter = batch_iter+opt.batch_size\n",
        "        total_step += 1\n",
        "        # Set variables for training\n",
        "        batch_img1 = batch_img1.float().to(dev)\n",
        "        batch_img2 = batch_img2.float().to(dev)\n",
        "        labels = labels.long().to(dev)\n",
        "\n",
        "        # Zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get model predictions, calculate loss, backprop\n",
        "        cd_preds = model(batch_img1, batch_img2)\n",
        "\n",
        "        cd_loss = criterion(cd_preds, labels)\n",
        "        loss = cd_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cd_preds = cd_preds[-1]\n",
        "        _, cd_preds = torch.max(cd_preds, 1)\n",
        "\n",
        "        # Calculate and log other batch metrics\n",
        "        cd_corrects = (100 *\n",
        "                       (cd_preds.squeeze().byte() == labels.squeeze().byte()).sum() /\n",
        "                       (labels.size()[0] * (opt.patch_size**2)))\n",
        "\n",
        "        cd_train_report = prfs(labels.data.cpu().numpy().flatten(),\n",
        "                               cd_preds.data.cpu().numpy().flatten(),\n",
        "                               average='binary',\n",
        "                               zero_division=0,\n",
        "                               pos_label=1)\n",
        "\n",
        "        train_metrics = set_metrics(train_metrics,\n",
        "                                    cd_loss,\n",
        "                                    cd_corrects,\n",
        "                                    cd_train_report,\n",
        "                                    scheduler.get_last_lr())\n",
        "\n",
        "        # log the batch mean metrics\n",
        "        mean_train_metrics = get_mean_metrics(train_metrics)\n",
        "\n",
        "        for k, v in mean_train_metrics.items():\n",
        "            writer.add_scalars(str(k), {'train': v}, total_step)\n",
        "\n",
        "        # clear batch variables from memory\n",
        "        del batch_img1, batch_img2, labels\n",
        "\n",
        "    scheduler.step()\n",
        "    logging.info(\"EPOCH {} TRAIN METRICS\".format(epoch) + str(mean_train_metrics))\n",
        "\n",
        "    \"\"\"\n",
        "    Begin Validation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_img1, batch_img2, labels in val_loader:\n",
        "            torch.cuda.empty_cache()\n",
        "            # Set variables for training\n",
        "            batch_img1 = batch_img1.float().to(dev)\n",
        "            batch_img2 = batch_img2.float().to(dev)\n",
        "            labels = labels.long().to(dev)\n",
        "\n",
        "            # Get predictions and calculate loss\n",
        "            cd_preds = model(batch_img1, batch_img2)\n",
        "\n",
        "            cd_loss = criterion(cd_preds, labels)\n",
        "\n",
        "            cd_preds = cd_preds[-1]\n",
        "            _, cd_preds = torch.max(cd_preds, 1)\n",
        "\n",
        "            # Calculate and log other batch metrics\n",
        "            cd_corrects = (100 *\n",
        "                           (cd_preds.squeeze().byte() == labels.squeeze().byte()).sum() /\n",
        "                           (labels.size()[0] * (opt.patch_size**2)))\n",
        "\n",
        "            cd_val_report = prfs(labels.data.cpu().numpy().flatten(),\n",
        "                                 cd_preds.data.cpu().numpy().flatten(),\n",
        "                                 average='binary',\n",
        "                                 zero_division=0,\n",
        "                                 pos_label=1)\n",
        "\n",
        "            val_metrics = set_metrics(val_metrics,\n",
        "                                      cd_loss,\n",
        "                                      cd_corrects,\n",
        "                                      cd_val_report,\n",
        "                                      scheduler.get_last_lr())\n",
        "\n",
        "            # log the batch mean metrics\n",
        "            mean_val_metrics = get_mean_metrics(val_metrics)\n",
        "\n",
        "            for k, v in mean_train_metrics.items():\n",
        "                writer.add_scalars(str(k), {'val': v}, total_step)\n",
        "\n",
        "            # clear batch variables from memory\n",
        "            del batch_img1, batch_img2, labels\n",
        "\n",
        "        logging.info(\"EPOCH {} VALIDATION METRICS\".format(epoch)+str(mean_val_metrics))\n",
        "\n",
        "        \"\"\"\n",
        "        Store the weights of good epochs based on validation results\n",
        "        \"\"\"\n",
        "        if ((mean_val_metrics['cd_precisions'] > best_metrics['cd_precisions'])\n",
        "                or\n",
        "                (mean_val_metrics['cd_recalls'] > best_metrics['cd_recalls'])\n",
        "                or\n",
        "                (mean_val_metrics['cd_f1scores'] > best_metrics['cd_f1scores'])):\n",
        "\n",
        "            # Insert training and epoch information to metadata dictionary\n",
        "            logging.info('updata the model')\n",
        "            metadata['validation_metrics'] = mean_val_metrics\n",
        "\n",
        "            # Save model and log\n",
        "            if not os.path.exists('./tmp'):\n",
        "                os.mkdir('./tmp')\n",
        "            with open('./tmp/metadata_epoch_' + str(epoch) + '.json', 'w') as fout:\n",
        "                json.dump(metadata, fout)\n",
        "\n",
        "            torch.save(model, './tmp/checkpoint_epoch_'+str(epoch)+'.pt')\n",
        "\n",
        "            # comet.log_asset(upload_metadata_file_path)\n",
        "            best_metrics = mean_val_metrics\n",
        "\n",
        "\n",
        "        print('An epoch finished.')\n",
        "writer.close()  # close tensor board\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "198abe375f91401eb291a0980d294bce",
            "bb9ddb9d77bb447d82ed0359d3b0df9b",
            "1a02a54a0fb946cbb3c4bb4159e65ad5",
            "05066ef9540048b78466dfc1790e915a",
            "ed78d6b766fa4ba99a667bc83e604d0f",
            "6b530aca4caa4bbdbfc7b513191eb2a1",
            "538951e679764b33918df9f7c95e13a3",
            "ba2d2d2fa0f0467ba443af0988e47010",
            "1450abc1e9f041e2aa3d43e5ef348c8f",
            "4206d9d9d8884c0da337e0406537f8d1",
            "4c1f435404024bd29d8e2a2a84e258ba"
          ]
        },
        "id": "aYLcGgXI8mue",
        "outputId": "cd2d7e5d-a6c3-4976-93ce-b78250b01390"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/220 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "198abe375f91401eb291a0980d294bce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b730e5cdd5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Get model predictions, calculate loss, backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcd_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mcd_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/Models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xA, xB)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m'''xA'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx0_0A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mx1_0A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0_0A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mx2_0A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_0A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/Models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 14.75 GiB total capacity; 13.57 GiB already allocated; 120.81 MiB free; 13.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}